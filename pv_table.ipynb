{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9839fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   observation_id        object_name observation_start_time  resolve_exposure\n",
      "0       000151000   Abell2029_Center    2024-01-13 01:51:04            29.337\n",
      "1       000149000   Abell2029_Center    2024-01-10 03:31:04            16.324\n",
      "2       000147000        Abell2029_E    2024-01-09 00:41:04            23.026\n",
      "3       000146000        Abell2029_N    2024-01-08 14:41:04            20.112\n",
      "4       000150000       Abell2029_N1    2024-01-10 16:21:04           106.210\n",
      "5       300053010       Abell2029_N2    2024-07-27 16:16:04           383.186\n",
      "6       000152000       Abell2029_N2    2024-01-13 19:31:04            50.437\n",
      "7       000148000       Abell2029_SW    2024-01-09 14:41:04            27.591\n",
      "8       000103000          Abell2319    2023-10-19 23:51:04            97.672\n",
      "9       000101000          Abell2319    2023-10-13 23:51:04           146.644\n",
      "10      000153000       Abell2319_BS    2024-01-15 00:01:04            11.603\n",
      "11      000113000       Abell2319_BS    2023-11-11 12:01:04            94.756\n",
      "12      000106000       Abell2319_BS    2023-11-03 15:31:04             0.000\n",
      "13      000104200       Abell2319_BS    2023-10-29 00:01:04           241.787\n",
      "14      000104100       Abell2319_BS    2023-10-26 00:01:04           153.775\n",
      "15      000104000       Abell2319_BS    2023-10-23 20:31:04           101.905\n",
      "16      000111000       Abell2319_BS    2023-11-06 13:11:04           101.349\n",
      "17      000153100       Abell2319_BS    2024-01-15 05:34:31             2.778\n",
      "18      000100000       Abell2319_BS    2023-10-09 02:01:04           234.129\n",
      "19      000153300       Abell2319_BS    2024-01-19 02:45:04            26.861\n",
      "20      000153400       Abell2319_BS    2024-01-20 01:33:59             0.000\n",
      "21      000153200       Abell2319_BS    2024-01-18 02:44:24             0.000\n",
      "22      000114000      Abell2319_BS2    2023-11-13 10:21:04           145.436\n",
      "23      000102000     Abell2319_Cor1    2023-10-17 01:29:37           140.565\n",
      "24      300019010        CENTAURUS_A    2024-08-04 19:17:04           227.986\n",
      "25      000138000  Centaurus_Cluster    2023-12-28 00:01:04           298.446\n",
      "26      300073010        COMA_CENTER    2024-07-09 07:17:04           402.101\n",
      "27      300074010        COMA_OFFSET    2024-05-20 12:05:04            89.819\n",
      "28      300074020        COMA_OFFSET    2024-05-22 23:57:04            81.201\n",
      "29      300014010                M87    2024-06-13 08:14:04           121.725\n",
      "30      300015010          M87_E_ARM    2024-05-30 09:01:04           168.098\n",
      "31      300016010             M87_NW    2024-05-26 04:29:04            29.138\n",
      "32      300016020             M87_NW    2024-05-27 05:51:04           151.639\n",
      "33      300017020         M87_SW_ARM    2024-12-09 02:22:04            82.049\n",
      "34      300017010         M87_SW_ARM    2024-06-02 20:01:04            78.289\n",
      "35      000156000         Perseus_C1    2024-01-23 08:56:04            63.848\n",
      "36      000154000       Perseus_CAL1    2024-01-21 00:31:04            50.733\n",
      "37      000155000       Perseus_CAL2    2024-01-22 05:36:04            55.927\n",
      "38      000157000         Perseus_M1    2024-01-24 16:56:04           105.138\n",
      "39      000158000         Perseus_O1    2024-01-26 21:10:04           139.965\n",
      "40      000112000        PKS_0745-19    2023-11-08 10:21:04           143.663\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = (\n",
    "    \"https://darts.isas.jaxa.jp/app/query/astroquery/sql.php?\"\n",
    "    \"format=html&\"\n",
    "    \"sql=\"\n",
    "    \"SELECT%0A\"\n",
    "    \"observation_id%2Cobject_name%2Ccenter_ra%2Ccenter_dec%2C\"\n",
    "    \"roll_angle%2Cobservation_start_time%2Cobservation_end_time%2C\"\n",
    "    \"resolve_exposure%2Cxtend_exposure%2Cprocessing_date%2Cpublic_date%2C\"\n",
    "    \"distribution_date%2Cprocessing_version%2Cdata_access_url%0A\"\n",
    "    \"FROM%20xrism_master_data%0A\"\n",
    "    \"where%20observation_start_time_mjd%20%3E%2060209%0A\"\n",
    "    \"order%20by%20observation_start_time%20desc\"\n",
    ")\n",
    "\n",
    "# observation_id を文字列として読み込む\n",
    "df = pd.read_html(url, header=0, converters={\"observation_id\": str})[0]\n",
    "\n",
    "# 最左列が行番号なら削除\n",
    "if df.columns[0] == 0:\n",
    "    df = df.drop(columns=df.columns[0])\n",
    "\n",
    "# 列名整形\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "# ① obsid が 0 または 3 で始まる行\n",
    "mask_obsid = df[\"observation_id\"].astype(str).str.startswith((\"0\", \"3\"), na=False)\n",
    "\n",
    "# ② ターゲット名のマスク（大小・空白無視にするため前処理）\n",
    "targets   = [\"perseus\", \"m87\", \"abell2029\", \"coma\",\n",
    "             \"centaurus\", \"abell2319\", \"pks_0745\"]\n",
    "\n",
    "# object_name を小文字化 → 連続する空白を除去してから判定\n",
    "name_norm = (\n",
    "    df[\"object_name\"]\n",
    "      .astype(str)\n",
    "      .str.lower()\n",
    "      .str.replace(r\"\\s+\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "mask_target = name_norm.str.contains(\"|\".join(targets))\n",
    "\n",
    "# --- 条件を両方満たす行だけ抜き出す ------------------\n",
    "df_sel = df[mask_obsid & mask_target].reset_index(drop=True)\n",
    "\n",
    "# 大文字・小文字を無視して object_name でソート\n",
    "df_sorted = (\n",
    "    df_sel\n",
    "    .sort_values(\n",
    "        by=\"object_name\",\n",
    "        key=lambda col: col.str.lower()   # col.str.lower() で小文字化して比較\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 必要な列だけを表示して確認\n",
    "print(\n",
    "    df_sorted[\n",
    "        [\"observation_id\", \"object_name\",\n",
    "         \"observation_start_time\", \"resolve_exposure\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1894e9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ /Users/keitatanaka/Dropbox/XRISM_PV_archive/xrism_egd_bybasename.xlsx に保存しました\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ─────────────────── 0) データ取得は以前と同じ ───────────────────\n",
    "df = pd.read_html(\n",
    "    url,\n",
    "    header=0,\n",
    "    converters={\"observation_id\": str, \"public_date\": str}  # public_date を文字列で保持\n",
    ")[0]\n",
    "if df.columns[0] == 0:\n",
    "    df = df.drop(columns=df.columns[0])\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# ─────────────────── 1) 公開日フィルタ (2025-08-31) ───────────────────\n",
    "#   - public_date 列は \"YYYY-MM-DD …\" 形式なので startswith が簡単\n",
    "mask_pub = df[\"public_date\"].str.startswith(\"2025-08-31\", na=False)\n",
    "\n",
    "# ─────────────────── 2) ターゲット名フィルタ (大文字小文字無視) ───────────────────\n",
    "targets = [\n",
    "    \"perseus\", \"m87\", \"abell2029\", \"coma\",\n",
    "    \"centaurus\", \"abell2319\", \"pks_0745\"\n",
    "]\n",
    "name_norm = (\n",
    "    df[\"object_name\"]\n",
    "      .astype(str)\n",
    "      .str.lower()\n",
    "      .str.replace(r\"\\s+\", \"\", regex=True)\n",
    ")\n",
    "mask_tgt = name_norm.str.contains(\"|\".join(targets))\n",
    "\n",
    "# ─────────────────── 3) 両方満たす行だけ抽出 ───────────────────\n",
    "df_sel = df[mask_pub & mask_tgt].reset_index(drop=True)\n",
    "\n",
    "# ─────────────────── 4) アルファベット順ソート ───────────────────\n",
    "df_sorted = (\n",
    "    df_sel.sort_values(\n",
    "        by=\"object_name\",\n",
    "        key=lambda col: col.str.lower()\n",
    "    ).reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# ─────────────────── 5) “ベース名”列を作り色付け ───────────────────\n",
    "base_keys = [\n",
    "    \"abell2029\", \"abell2319\", \"centaurus\", \"coma\",\n",
    "    \"m87\", \"perseus\", \"pks0745\"\n",
    "]\n",
    "\n",
    "def extract_basename(name: str) -> str:\n",
    "    norm = name.lower().replace(\" \", \"\")\n",
    "    for key in base_keys:\n",
    "        if key in norm:\n",
    "            return key\n",
    "    return \"other\"\n",
    "\n",
    "df_sorted[\"base_name\"] = df_sorted[\"object_name\"].apply(extract_basename)\n",
    "\n",
    "palette = [\"#FFCCCC\", \"#CCFFCC\", \"#CCCCFF\", \"#FFF2CC\",\n",
    "           \"#D5E8D4\", \"#F8CECC\", \"#E1D5E7\"]\n",
    "color_map = {b: palette[i % len(palette)]\n",
    "             for i, b in enumerate(df_sorted[\"base_name\"].unique())}\n",
    "\n",
    "def highlight_row(row):\n",
    "    return [f\"background-color: {color_map[row['base_name']]}\"] * len(row)\n",
    "\n",
    "styled = (\n",
    "    df_sorted\n",
    "      .style\n",
    "      .apply(highlight_row, axis=1)\n",
    "      .hide(axis=\"columns\", subset=[\"base_name\"])\n",
    ")\n",
    "\n",
    "# ─────────────────── 6) Excel 出力 ───────────────────\n",
    "out = Path(\"/Users/keitatanaka/Dropbox/XRISM_PV_archive/xrism_egd_bybasename.xlsx\")\n",
    "styled.to_excel(out, index=False, engine=\"openpyxl\")   # openpyxl を事前に pip install\n",
    "print(f\"→ {out} に保存しました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf89fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
